机器翻译，又称为自动翻译，是利用计算机将一种自然语言(源语言)转换为另一种自然语言(目标语言)的过程。它是计算语言学的一个分支，是人工智能的终极目标之一，具有重要的科学研究价值。
同时，机器翻译又具有重要的实用价值。随着经济全球化及互联网的飞速发展，机器翻译技术在促进政治、经济、文化交流等方面起到越来越重要的作用。
机器翻译技术的发展一直与计算机技术、信息论、语言学等学科的发展紧密相随。从早期的词典匹配，到词典结合语言学专家知识的规则翻译，再到基于语料库的统计机器翻译，随着计算机计算能力的提升和多语言信息的爆发式增长，机器翻译技术逐渐走出象牙塔，开始为普通用户提供实时便捷的翻译服务。
机器翻译的研究历史可以追溯到 20 世纪三四十年代。20世纪30年代初，法国科学家G.B.阿尔楚尼提出了用机器来进行翻译的想法。1933年，苏联发明家П.П.特罗扬斯基设计了把一种语言翻译成另一种语言的机器，并在同年9月5日登记了他的发明；但是，由于30年代技术水平还很低，他的翻译机没有制成。1946 年，第一台现代电子计算机 ENIAC 诞生，随后不久，信息论的先驱、美国科学家 W. Weaver 和英国工程师A. D. Booth 在讨论电子计算机的应用范围时，于1947年提出了利用计算机进行语言自动翻译的想法。1949年，W. Weaver 发表《翻译备忘录》 ，正式提出机器翻译的思想。走过六十年的风风雨雨，机器翻译经历了一条曲折而漫长的发展道路，学术界一般将其划分为如下四个阶段：
（1947-1964）
1954 年，美国乔治敦大学（Georgetown University） 在 IBM 公司协同下， 用 IBM-701计算机首次完成了英俄机器翻译试验，向公众和科学界展示了机器翻译的可行性，从而拉开了机器翻译研究的序幕。
中国开始这项研究也并不晚， 早在1956年，国家就把这项研究列入了全国科学工作发展规划，课题名称是“机器翻译、自然语言翻译规则的建设和自然语言的数学理论”。1957 年，中国科学院语言研究所与计算技术研究所合作开展俄汉机器翻译试验，翻译了9 种不同类型的较为复杂的句子。
从20世纪50年代开始到20世纪60年代前半期，机器翻译研究呈不断上升的趋势。美国和前苏联两个超级大国出于军事、政治、经济目的，均对机器翻译项目提供了大量的资金支持，而欧洲国家由于地缘政治和经济的需要也对机器翻译研究给予了相当大的重视，机器翻译一时出现热潮。这个时期机器翻译虽然刚刚处于开创阶段，但已经进入了乐观的繁荣期。
（1964-1975）
1964年，为了对机器翻译的研究进展作出评价，美国科学院成立了语言自动处理咨询委员会(Automatic Language Processing Advisory Committee，简称ALPAC委员会)，开始了为期两年的综合调查分析和测试。
1966年11月，该委员会公布了一个题为《语言与机器》的报告（简称ALPAC报告） ，该报告全面否定了机器翻译的可行性，并建议停止对机器翻译项目的资金支持。这一报告的发表给了正在蓬勃发展的机器翻译当头一棒，机器翻译研究陷入了近乎停滞的僵局。无独有偶，在此期间，中国爆发了“十年文革” ，基本上这些研究也停滞了。机器翻译步入萧条期。
（1975-1989）
进入 70 年代后，随着科学技术的发展和各国科技情报交流的日趋频繁，国与国之间的语言障碍显得更为严重，传统的人工作业方式已经远远不能满足需求，迫切地需要计算机来从事翻译工作。 同时，计算机科学、语言学研究的发展，特别是计算机硬件技术的大幅度提高以及人工智能在自然语言处理上的应用，从技术层面推动了机器翻译研究的复苏，机器翻译项目又开始发展起来，各种实用的以及实验的系统被先后推出，例如 Weinder 系统、EURPOTRA 多国语翻译系统、TAUM-METEO系统等。
而我国在“十年浩劫”结束后也重新振作起来，机器翻译研究被再次提上日程。“784”工程给予了机器翻译研究足够的重视，80 年代中期以后，我国的机器翻译研究发展进一步加快，首先研制成功了 KY-1 和MT/EC863 两个英汉机译系统，表明我国在机器翻译技术方面取得了长足的进步。
（1990至今）
随着 Internet 的普遍应用，世界经济一体化进程的加速以及国际社会交流的日渐频繁，传统的人工作业的方式已经远远不能满足迅猛增长的翻译需求，人们对于机器翻译的需求空前增长，机器翻译迎来了一个新的发展机遇。国际性的关于机器翻译研究的会议频繁召开，中国也取得了前所未有的成就，相继推出了一系列机器翻译软件，例如“译星” 、 “雅信” 、 “通译” 、 “华建”等。在市场需求的推动下，商用机器翻译系统迈入了实用化阶段，走进了市场，来到了用户面前。
新世纪以来，随着互联网的出现和普及，数据量激增，统计方法得到充分应用。互联网公司纷纷成立机器翻译研究组，研发了基于互联网大数据的机器翻译系统，从而使机器翻译真正走向实用，例如“百度翻译”，“谷歌翻译”等。近年来，随着深度学习的进展，机器翻译技术的到了进一步的发展，促进了翻译质量的快速提升，在口语等领域的翻译更加地道流畅。
整个机器翻译的过程可以分为原文分析、原文译文转换和译文生成3个阶段。在具体的机器翻译系统中，根据不同方案的目的和要求，可以将原文译文转换阶段与原文分析阶段结合在一起，而把译文生成阶段独立起来，建立相关分析独立生成系统。在这样的系统中，原语分析时要考虑译语的特点，而在译语生成时则不考虑原语的特点。在研究多种语言对一种语言的翻译时，宜于采用这样的相关分析独立生成系统。也可以把原文分析阶段独立起来，把原文译文转换阶段同译文生成阶段结合起来，建立独立分析相关生成系统。在这样的系统中，原语分析时不考虑译语的特点，而在译语生成时要考虑原语的特点，在研究一种语言对多种语言的翻译时，宜于采用这样的独立分析相关生成系统。还可以把原文分析、原文译文转换与译文生成分别独立开来，建立独立分析独立生成系统。在这样的系统中，分析原语时不考虑译语的特点，生成译语时也不考虑原语的特点，原语译语的差异通过原文译文转换来解决。在研究多种语言对多种语言的翻译时，宜于采用这样的独立分析独立生成系统。
中国机器翻译研究起步于1957年,是世界上第4个开始研究机器翻译的国家，60年代中期以后一度中断，70年代中期以来有了进一步的发展。中国社会科学院语言研究所、中国科学技术情报研究所、中国科学院计算技术研究所、黑龙江大学、哈尔滨工业大学等单位都在进行机器翻译的研究；上机进行过实验的机器翻译系统已有十多个，翻译的语种和类型有英汉、俄汉、法汉、日汉、德汉等一对一的系统,也有汉译英、法、日、俄、德的一对多系统（FAJRA系统）。此外，还建立了一个汉语语料库和一个科技英语语料库。中国机器翻译系统的规模正在不断地扩大，内容正在不断地完善。近年来，中国的互联网公司也发布了互联网翻译系统，如“百度翻译”“有道翻译”等。
机译系统可划分为基于规则（ Rule-Based ）和基于语料库（Corpus-Based）两大类。前者由词典和规则库构成知识源；后者由经过划分并具有标注的语料库构成知识源，既不需要词典也不需要规则，以统计规律为主。机译系统是随着语料库语言学的兴起而发展起来的，世界上绝大多数机译系统都采用以规则为基础的策略，一般分为语法型、语义型、知识型和智能型。不同类型的机译系统由不同的成分构成。抽象地说，所有机译系统的处理过程都包括以下步骤：对源语言的分析或理解，在语言的某一平面进行转换，按目标语言结构规则生成目标语言。技术差别主要体现在转换平面上。
从美国乔治敦大学的机器翻译试验到50年代末的系统，基本上属于这一类机器翻译系统。它们的特点是:①以词汇转换为中心，建立双语词典,翻译时,文句加工的目的在于立即确定相应于原语各个词的译语等价词；②如果原语的一个词对应于译语的若干个词，机器翻译系统本身并不能决定选择哪一个，而只能把各种可能的选择全都输出；③语言和程序不分，语法的规则与程序的算法混在一起，算法就是规则。由于第一类机器翻译系统的上述特点，它的译文质量是极为低劣的，并且，设计这样的系统是一种十分琐碎而繁杂的工作，系统设计成之后没有扩展的余地，修改时牵一发而动全身，给系统的改进造成极大困难。
研究重点是词法和句法，以上下文无关文法为代表，早期系统大多数都属这一类型。语法型系统包括源文分析机构、源语言到目标语言的转换机构和目标语言生成机构3部分。源文分析机构对输入的源文加以分析，这一分析过程通常又可分为词法分析、语法分析和语义分析。通过上述分析可以得到源文的某种形式的内部表示。转换机构用于实现将相对独立于源文表层表达方式的内部表示转换为与目标语言相对应的内部表示。目标语言生成机构实现从目标语言内部表示到目标语言表层结构的转化。
60年代以来建立的机器翻译系统绝大部分是这一类机器翻译系统。它们的特点是：①把句法的研究放在第一位，首先用代码化的结构标志来表示原语文句的结构，再把原语的结构标志转换为译语的结构标志，最后构成译语的输出文句;②对于多义词必须进行专门的处理,根据上下文关系选择出恰当的词义，不容许把若干个译文词一揽子列出来；③语法与算法分开，在一定的条件之下，使语法处于一定类别的界限之内，使语法能由给定的算法来计算，并可由这种给定的算法描写为相应的公式，从而不改变算法也能进行语法的变换，这样，语法的编写和修改就可以不考虑算法。第2类机器翻译系统不论在译文的质量上还是在使用的方便上,都比第1类机器翻译系统大大地前进了一步。
研究重点是在机译过程中引入语义特征信息，以Burtop提出的语义文法和Charles Fillmore提出的格框架文法为代表。语义分析的各种理论和方法主要解决形式和逻辑的统一问题。利用系统中的语义切分规则，把输入的源文切分成若干个相关的语义元成分。再根据语义转化规则，如关键词匹配，找出各语义元成分所对应的语义内部表示。系统通过测试各语义元成分之间的关系，建立它们之间的逻辑关系，形成全文的语义表示。处理过程主要通过查语义词典的方法实现。语义表示形式一般为格框架，也可以是概念依存表示形式。最后，机译系统通过对中间语义表示形式的解释，形成相应的译文。
70年代以来，有些机器翻译者提出了以语义为主的第3类机器翻译系统。引入语义平面之后,就要求在语言描写方面作一些实质性的改变，因为在以句法为主的机器翻译系统中,最小的翻译单位是词,最大的翻译单位是单个的句子，机器翻译的算法只考虑对一个句子的自动加工，而不考虑分属不同句子的词与词之间的联系。第3类机器翻译系统必须超出句子范围来考虑问题,除了义素、词、词组、句子之外，还要研究大于句子的句段和篇章。为了建立第3类机器翻译系统,语言学家要深入研究语义学,数学家要制定语义表示和语义加工的算法,在程序设计方面，也要考虑语义加工的特点。
目标是给机器配上人类常识，以实现基于理解的翻译系统，以Tomita提出的知识型机译系统为代表。知识型机译系统利用庞大的语义知识库，把源文转化为中间语义表示，并利用专业知识和日常知识对其加以精练，最后把它转化为一种或多种译文输出。
目标是采用人工智能的最新成果，实现多路径动态选择以及知识库的自动重组技术，对不同句子实施在不同平面上的转换。这样就可以把语法、语义、常识几个平面连成一有机整体，既可继承传统系统优点，又能实现系统自增长的功能。这一类型的系统以中国科学院计算所开发的IMT/EC系统为代表。
一般的基于语料库（Corpus-Based）的机译系统就是基于统计的机器翻译，因为这一领域异军突起，统计就是统计平行语料，由此衍生出许多不同的统计模型。
不同于基于规则的机译系统由词典和语法规则库构成翻译知识库，基于语料库的机译系统是以语料的应用为核心，由经过划分并具有标注的语料库构成知识库。基于语料库的方法可以分为基于统计（Statistics-based）的方法和基于实例（Example-based）的方法。
基于统计的机器翻译
基于统计的机器翻译方法把机器翻译看成是一个信息传输的过程，用一种信道模型对机器翻译进行解释。这种思想认为，源语言句子到目标语言句子的翻译是一个概率问题，任何一个目标语言句子都有可能是任何一个源语言句子的译文，只是概率不同，机器翻译的任务就是找到概率最大的句子。具体方法是将翻译看做对原文通过模型转换为译文的解码过程。因此统计机器翻译又可以分为以下几个问题：模型问题、训练问题、解码问题。所谓模型问题，就是为机器翻译建立概率模型，也就是要定义源语言句子到目标语言句子的翻译概率的计算方法。而训练问题，是要利用语料库来得到这个模型的所有参数。所谓解码问题，则是在已知模型和参数的基础上，对于任何一个输入的源语言句子，去查找概率最大的译文。
实际上， 用统计学方法解决机器翻译问题的想法并非是 20 世纪 90 年代的全新思想，1949 年W. Weaver 在那个机器翻译备忘录就已经提出使用这种方法，只是由于乔姆斯基(N.Chomsky) 等人对计的批判，这种方法很快就被放弃了。批判的理由主要是一点：语言是无限的，基于经验主义的统计描述无法满足语言的实际要求。
另外，限于当时的计算机速度，统计的价值也无从谈起。计算机不论从速度还是从容量方面都有了大幅度的提高，昔日大型计算机才能完成的工作，今日小型工作站或个人计算机就可以完成了。此外，统计方法在语音识别、文字识别、词典编纂等领域的成功应用也表明这一方法在语言自动处理领域还是很有成效的。
统计机器翻译方法的数学模型是由国际商业机器公司 （IBM） 的研究人员提出的。在著名的文章《机器翻译的数学理论》中提出了由五种词到词的统计模型，称为 IBM 模型 1 到 IBM 模型 5。这五种模型均源自信源-信道模型，采用最大似然法估计参数。由于当时（1993年）计算条件的限制，无法实现基于大规模数据训练。其后，由Stephan Vogel提出了基于隐马尔科夫模型的统计模型也受到重视，该模型被用来替代IBM Model 2。在这时的研究中，统计模型只考虑了词与词之间的线性关系，没有考虑句子的结构。这在两种语言的语序相差较大时效果可能不会太好。如果在考虑语言模型和翻译模型时将句法结构或语义结构考虑进来，应该会得到更好的结果。
在此文发表后6年，一批研究人员在约翰·霍普金斯大学的机器翻译夏令营上实现了GIZA软件包。Franz Joseph Och 在随后对该软件进行了优化，加快训练速度。特别是IBM Model 3 到 5的训练。同时他提出了更加复杂的Model 6。Och发布的软件包被命名为GIZA++，直到现在，GIZA++还是绝大部分统计机器翻译系统的基石。针对大规模语料的训练，已有GIZA++的若干并行化版本存在。
基于词的统计机器翻译的性能却由于建模单元过小而受到限制。因此，许多研究者开始转向基于短语的翻译方法。Franz-Josef Och提出的基于最大熵模型的区分性训练方法使统计机器翻译的性能极大提高，在此后数年，该方法的性能远远领先于其他方法。一年后Och又修改最大熵方法的优化准则，直接针对客观评价标准进行优化，从而诞生了今天广泛采用的最小错误训练方法(Minimum Error Rate Training)。
另一件促进统计机器翻译进一步发展的重要发明是自动客观评价方法的出现，为翻译结果提供了自动评价的途径，从而避免了繁琐与昂贵的人工评价。最为重要的评价是BLEU评价指标。绝大部分研究者仍然使用BLEU作为评价其研究结果的首要的标准。
Moses 是维护较好的开源机器翻译软件，由爱丁堡大学研究人员组织开发。其发布使得以往繁琐复杂的处理简单化。
Google 的在线翻译已为人熟知，其背后的技术即为基于统计的机器翻译方法，基本运行原理是通过搜索大量的双语网页内容，将其作为语料库，然后由计算机自动选取最为常见的词与词的对应关系，最后给出翻译结果。不可否认，Google 采用的技术是先进的，但它还是经常闹出各种“翻译笑话” 。其原因在于：基于统计的方法需要大规模双语语料，翻译模型、语言模型参数的准确性直接依赖于语料的多少，而翻译质量的高低主要取决于概率模型的好坏和语料库的覆盖能力。基于统计的方法虽然不需要依赖大量知识，直接靠统计结果进行歧义消解处理和译文选择，避开了语言理解的诸多难题，但语料的选择和处理工程量巨大。因此通用领域的机器翻译系统很少以统计方法为主。
基于实例的机器翻译
与统计方法相同，基于实例的机器翻译方法也是一种基于语料库的方法，其基本思想由日本著名的机器翻译专家长尾真提出，他研究了外语初学者的基本模式，发现初学外语的人总是先记住最基本的英语句子和对应的日语句子，而后做替换练习。参照这个学习过程，他提出了基于实例的机器翻译思想，即不经过深层分析，仅仅通过已有的经验知识，通过类比原理进行翻译。其翻译过程是首先将源语言正确分解为句子，再分解为短语碎片，接着通过类比的方法把这些短语碎片译成目标语言短语，最后把这些短语合并成长句。对于实例方法的系统而言，其主要知识源就是双语对照的实例库，不需要什么字典、语法规则库之类的东西，核心的问题就是通过最大限度的统计，得出双语对照实例库。
基于实例的机器翻译对于相同或相似文本的翻译有非常显著的效果，随着例句库规模的增加，其作用也越来越显著。对于实例库中的已有文本，可以直接获得高质量的翻译结果。对与实例库中存在的实例十分相似的文本，可以通过类比推理，并对翻译结果进行少量的修改，构造出近似的翻译结果。
这种方法在初推之时，得到了很多人的推崇。但一段时期后，问题出现了。由于该方法需要一个很大的语料库作为支撑，语言的实际需求量非常庞大。但受限于语料库规模，基于实例的机器翻译很难达到较高的匹配率，往往只有限定在比较窄的或者专业的领域时，翻译效果才能达到使用要求。因而到目前为止，还很少有机器翻译系统采用纯粹的基于实例的方法，一般都是把基于实例的机器翻译方法作为多翻译引擎中的一个，以提高翻译的正确率。
2013年来，随着深度学习的研究取得较大进展，基于人工神经网络的机器翻译（ Neural Machine Translation ）逐渐兴起。其技术核心是一个拥有海量结点（神经元）的深度神经网络，可以自动的从语料库中学习翻译知识。一种语言的句子被向量化之后，在网络中层层传递，转化为计算机可以“理解”的表示形式，再经过多层复杂的传导运算，生成另一种语言的译文。实现了 “理解语言，生成译文”的翻译方式。这种翻译方法最大的优势在于译文流畅，更加符合语法规范，容易理解。相比之前的翻译技术，质量有“跃进式”的提升。
目前，广泛应用于机器翻译的是长短时记忆（LSTM，Long Short-Term Memory）循环神经网络(RNN，Recurrent Neural Network)。该模型擅长对自然语言建模，把任意长度的句子转化为特定维度的浮点数向量，同时“记住”句子中比较重要的单词，让“记忆”保存比较长的时间。该模型很好地解决了自然语言句子向量化的难题，对利用计算机来处理自然语言来说具有非常重要的意义，使得计算机对语言的处理不再停留在简单的字面匹配层面，而是进一步深入到语义理解的层面。
代表性的研究机构和公司包括，加拿大蒙特利尔大学的机器学习实验室，发布了开源的基于神经网络的机器翻译系统GroundHog。2015年，百度发布了融合统计和深度学习方法的在线翻译系统，Google也在此方面开展了深入研究。
鉴于机器翻译仍具相当市场，中国涉足这一领域的厂商也不一而足。国内市场上的翻译软件产品可以划分为四大类：全文翻译（专业翻译）、在线翻译、汉化软件和电子词典。
全文翻译软件以中软“译星”以及“雅信CAT2.5”为代表；
随着全球化网络时代的到来，语言障碍已经成为二十一世纪社会发展的重要瓶颈，实现任意时间、任意地点、任意语言的无障碍自由沟通是人类追求的一个梦想。这仅是全球化背景下的一个小缩影。在社会快速发展的进程中，机器翻译扮演越来越重要的角色。
词典类软件如金山词霸，有道词典等，基于大数据的互联网机器翻译系统如百度翻译，谷歌翻译等。
汉化类翻译软件主要以“东方快车3000”为代表；
词曲工具软件以“金山词霸.net2001”为主要代表。
由于机器翻译在今后需要满足人们在浩瀚的互联网上方便地进行信息搜集的需求，于是很多翻译开发者在翻译准确度上下工夫的同时，开始注重结合用户的使用领域并进行方向性的开发。根据的市场发展看来，在新一轮的竞赛中，在线翻译前景十分看好。中国的网民已超4亿，并继续以极快速度增长。
很多人对机器翻译有误解，他们认为机器翻译偏差大，不能帮人们解决任何问题。其实其误差在所难免，原因在于，机器翻译运用语言学原理，机器自动识别语法，调用存储的词库，自动进行对应翻译，但是因语法、词法、句法发生变化或者不规则，出现错误是难免的，比如《大话西游》中“给我一个杀你的理由，先”之类状语后置的句子。机器毕竟是机器，没有人对语言的特殊感情，它怎么会感受“最是那一低头的温柔，像一朵水莲花不胜凉风的娇羞”的韵味？毕竟汉语因其词法、语法、句法的变化及其语境的更换，其意思大相径庭，就连很多国人都是丈二和尚——摸不着头脑，就别说机器了。
事实上，不论哪种方法，影响机译发展的最大因素在于译文的质量。就已有的成就来看，机译的质量离终极目标仍相差甚远。
中国数学家、语言学家周海中曾在论文《机器翻译五十年》中指出：要提高机译的译文质量，首先要解决的是语言本身问题而不是程序设计问题；单靠若干程序来做机译系统，肯定是无法提高机译的译文质量的。同时，他还指出：在人类尚未明了大脑是如何进行语言的模糊识别和逻辑判断的情况下，机译要想达到“信、达、雅”的程度是不可能的。这一观点恐怕道出了制约译文质量的瓶颈所在。
值得一提的是，美国发明家、未来学家雷·科兹威尔在接受《赫芬顿邮报》采访时预言，到2029年机译的质量将达到人工翻译的水平。对于这一论断，学术界还存在很多争议。
不论怎样，目前是人们对机译最为看好的时期，这种关注是建立在一个客观认识和理性思考的基础上的。我们也有理由相信：在计算机专家、语言学家、心理学家、逻辑学家和数学家的共同努力下，机译的瓶颈问题将会得以解决了。
