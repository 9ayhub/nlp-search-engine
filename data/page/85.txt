机器学习(Machine Learning, ML)是一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。
它是人工智能的核心，是使计算机具有智能的根本途径，其应用遍及人工智能的各个领域，它主要使用归纳、综合而不是演绎。
学习是人类具有的一种重要智能行为，但究竟什么是学习，长期以来却众说纷纭。社会学家、逻辑学家和心理学家都各有其不同的看法。
比如，Langley（1996) 定义的机器学习是“机器学习是一门人工智能的科学，该领域的主要研究对象是人工智能，特别是如何在经验学习中改善具体算法的性能”。（Machine learning is a science of the artificial. The field's main objects of study are artifacts, specifically algorithms that improve their performance with experience.'）
Tom Mitchell的机器学习(1997)对信息论中的一些概念有详细的解释,其中定义机器学习时提到，“机器学习是对能通过经验自动改进的计算机算法的研究”。（Machine Learning is the study of computer algorithms that improve automatically through experience.）
Alpaydin（2004）同时提出自己对机器学习的定义，“机器学习是用数据或以往的经验，以此优化计算机程序的性能标准。”（Machine learning is programming computers to optimize a performance criterion using example data or past experience.）
尽管如此，为了便于进行讨论和估计学科的进展，有必要对机器学习给出定义，即使这种定义是不完全的和不充分的。顾名思义， 机器学习是研究如何使用机器来模拟人类学习活动的一门学科。稍为严格的提法是：机器学习是一门研究机器获取新知识和新技能，并识别现有知识的学问。这里所说的“机器”，指的就是计算机，电子计算机，中子计算机、光子计算机或神经计算机等等。
机器能否象人类一样能具有学习能力呢？1959年美国的塞缪尔(Samuel)设计了一个下棋程序，这个程序具有学习能力，它可以在不断的对弈中改善自己的棋艺。4年后，这个程序战胜了设计者本人。又过了3年，这个程序战胜了美国一个保持8年之久的常胜不败的冠军。这个程序向人们展示了机器学习的能力，提出了许多令人深思的社会问题与哲学问题。
机器的能力是否能超过人的，很多持否定意见的人的一个主要论据是：机器是人造的，其性能和动作完全是由设计者规定的，因此无论如何其能力也不会超过设计者本人。这种意见对不具备学习能力的机器来说的确是对的，可是对具备学习能力的机器就值得考虑了，因为这种机器的能力在应用中不断地提高，过一段时间之后，设计者本人也不知它的能力到了何种水平。
机器学习有下面几种定义： “机器学习是一门人工智能的科学，该领域的主要研究对象是人工智能，特别是如何在经验学习中改善具体算法的性能”。 “机器学习是对能通过经验自动改进的计算机算法的研究”。 “机器学习是用数据或以往的经验，以此优化计算机程序的性能标准。” 一种经常引用的英文定义是：A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.
机器学习已经有了十分广泛的应用，例如：数据挖掘、计算机视觉、自然语言处理、生物特征识别、搜索引擎、医学诊断、检测信用卡欺诈、证券市场分析、DNA序列测序、语音和手写识别、战略游戏和机器人运用。
机器学习是人工智能研究较为年轻的分支，它的发展过程大体上可分为4个时期。
第一阶段是在20世纪50年代中叶到60年代中叶，属于热烈时期。
第二阶段是在20世纪60年代中叶至70年代中叶，被称为机器学习的冷静时期。
第三阶段是从20世纪70年代中叶至80年代中叶，称为复兴时期。
机器学习的最新阶段始于1986年。
机器学习进入新阶段的重要表现在下列诸方面：
(1) 机器学习已成为新的边缘学科并在高校形成一门课程。它综合应用心理学、生物学和神经生理学以及数学、自动化和计算机科学形成机器学习理论基础。
(2) 结合各种学习方法，取长补短的多种形式的集成学习系统研究正在兴起。特别是连接学习符号学习的耦合可以更好地解决连续性信号处理中知识与技能的获取与求精问题而受到重视。
(3) 机器学习与人工智能各种基础问题的统一性观点正在形成。例如学习与问题求解结合进行、知识表达便于学习的观点产生了通用智能系统SOAR的组块学习。类比学习与问题求解结合的基于案例方法已成为经验学习的重要方向。
(4) 各种学习方法的应用范围不断扩大，一部分已形成商品。归纳学习的知识获取工具已在诊断分类型专家系统中广泛使用。连接学习在声图文识别中占优势。分析学习已用于设计综合型专家系统。遗传算法与强化学习在工程控制中有较好的应用前景。与符号系统耦合的神经网络连接学习将在企业的智能管理与智能机器人运动规划中发挥作用。
(5) 与机器学习有关的学术活动空前活跃。国际上除每年一次的机器学习研讨会外，还有计算机学习理论会议以及遗传算法会议。
学习是一项复杂的智能活动，学习过程与推理过程是紧密相连的，按照学习中使用推理的多少，机器学习所采用的策略大体上可分为4种——机械学习、通过传授学习、类比学习和通过事例学习。学习中所用的推理越多，系统的能力越强。
表示学习系统的基本结构。环境向系统的学习部分提供某些信息，学习部分利用这些信息修改知识库，以增进系统执行部分完成任务的效能，执行部分根据知识库完成任务，同时把获得的信息反馈给学习部分。在具体的应用中，环境，知识库和执行部分决定了具体的工作内容，学习部分所需要解决的问题完全由上述3部分确定。下面我们分别叙述这3部分对设计学习系统的影响。
影响学习系统设计的最重要的因素是环境向系统提供的信息。或者更具体地说是信息的质量。知识库里存放的是指导执行部分动作的一般原则，但环境向学习系统提供的信息却是各种各样的。如果信息的质量比较高，与一般原则的差别比较小，则学习部分比较容易处理。如果向学习系统提供的是杂乱无章的指导执行具体动作的具体信息，则学习系统需要在获得足够数据之后，删除不必要的细节，进行总结推广，形成指导动作的一般原则，放入知识库，这样学习部分的任务就比较繁重，设计起来也较为困难。
因为学习系统获得的信息往往是不完全的，所以学习系统所进行的推理并不完全是可靠的，它总结出来的规则可能正确，也可能不正确。这要通过执行效果加以检验。正确的规则能使系统的效能提高，应予保留；不正确的规则应予修改或从数据库中删除。
知识库是影响学习系统设计的第二个因素。知识的表示有多种形式，比如特征向量、一阶逻辑语句、产生式规则、语义网络和框架等等。这些表示方式各有其特点，在选择表示方式时要兼顾以下4个方面：
(1)表达能力强。
(2)易于推理。
(3)容易修改知识库。
(4)知识表示易于扩展。
对于知识库最后需要说明的一个问题是学习系统不能在全然没有任何知识的情况下凭空获取知识，每一个学习系统都要求具有某些知识理解环境提供的信息，分析比较，做出假设，检验并修改这些假设。因此，更确切地说，学习系统是对现有知识的扩展和改进。
执行部分是整个学习系统的核心，因为执行部分的动作就是学习部分力求改进的动作。同执行部分有关的问题有3个：复杂性、反馈和透明性。
本程序将根据您的评价判断执行结果 "1+1=2"　　实际上仅用了最简单的 if else for 语句　　这就是一个机器学习的例子，通过环境影响来进行学习。　　通过本例我们不难看出，在人工错误的引导下，机器会给出错误的答案 1+1不等于2。　　所以此类学习方法，一定要在正确引导下实践，否则会得到最坏的结果。　　学习完毕后，计算机会记录本次学习结果，存入数据库，下次执行相应任务时，再将结果调出执行。
基于学习策略的分类
学习策略是指学习过程中系统所采用的推理策略。一个学习系统总是由学习和环境两部分组成。由环境（如书本或教师）提供信息，学习部分则实现信息转换，用能够理解的形式记忆下来，并从中获取有用的信息。在学习过程中，学生（学习部分）使用的推理越少，他对教师（环境）的依赖就越大，教师的负担也就越重。学习策略的分类标准就是根据学生实现信息转换所需的推理多少和难易程度来分类的，依从简单到复杂，从少到多的次序分为以下六种基本类型：
1）机械学习 (Rote learning)
学习者无需任何推理或其它的知识转换，直接吸取环境所提供的信息。如塞缪尔的跳棋程序，纽厄尔和西蒙的LT系统。这类学习系统主要考虑的是如何索引存贮的知识并加以利用。系统的学习方法是直接通过事先编好、构造好的程序来学习，学习者不作任何工作，或者是通过直接接收既定的事实和数据进行学习，对输入信息不作任何的推理。
2）示教学习 (Learning from instruction或Learning by being told)
学生从环境（教师或其它信息源如教科书等）获取信息，把知识转换成内部可使用的表示形式，并将新的知识和原有知识有机地结合为一体。所以要求学生有一定程度的推理能力，但环境仍要做大量的工作。教师以某种形式提出和组织知识，以使学生拥有的知识可以不断地增加。这种学习方法和人类社会的学校教学方式相似，学习的任务就是建立一个系统，使它能接受教导和建议，并有效地存贮和应用学到的知识。不少专家系统在建立知识库时使用这种方法去实现知识获取。示教学习的一个典型应用例是FOO程序。
3）演绎学习 (Learning by deduction)
学生所用的推理形式为演绎推理。推理从公理出发，经过逻辑变换推导出结论。这种推理是"保真"变换和特化(specialization)的过程，使学生在推理过程中可以获取有用的知识。这种学习方法包含宏操作(macro-operation)学习、知识编辑和组块(Chunking)技术。演绎推理的逆过程是归纳推理。
4）类比学习 (Learning by analogy)
利用二个不同领域（源域、目标域）中的知识相似性，可以通过类比，从源域的知识（包括相似的特征和其它性质）推导出目标域的相应知识，从而实现学习。类比学习系统可以使一个已有的计算机应用系统转变为适应于新的领域，来完成原先没有设计的相类似的功能。
类比学习需要比上述三种学习方式更多的推理。它一般要求先从知识源（源域）中检索出可用的知识，再将其转换成新的形式，用到新的状况（目标域）中去。类比学习在人类科学技术发展史上起着重要作用，许多科学发现就是通过类比得到的。例如著名的卢瑟福类比就是通过将原子结构（目标域）同太阳系（源域）作类比，揭示了原子结构的奥秘。
5）基于解释的学习 (Explanation-based learning, EBL)
学生根据教师提供的目标概念、该概念的一个例子、领域理论及可操作准则，首先构造一个解释来说明为什么该例子满足目标概念，然后将解释推广为目标概念的一个满足可操作准则的充分条件。EBL已被广泛应用于知识库求精和改善系统的性能。
著名的EBL系统有迪乔恩（G.DeJong）的GENESIS,米切尔（T.Mitchell）的LEXII和LEAP, 以及明顿（S.Minton）等的PRODIGY。
6）归纳学习 (Learning from induction)
归纳学习是由教师或环境提供某概念的一些实例或反例，让学生通过归纳推理得出该概念的一般描述。这种学习的推理工作量远多于示教学习和演绎学习，因为环境并不提供一般性概念描述（如公理）。从某种程度上说，归纳学习的推理量也比类比学习大，因为没有一个类似的概念可以作为"源概念"加以取用。归纳学习是最基本的，发展也较为成熟的学习方法，在人工智能领域中已经得到广泛的研究和应用。
基于所获取知识的表示形式分类
学习系统获取的知识可能有：行为规则、物理对象的描述、问题求解策略、各种分类及其它用于任务实现的知识类型。
对于学习中获取的知识，主要有以下一些表示形式：
1）代数表达式参数
学习的目标是调节一个固定函数形式的代数表达式参数或系数来达到一个理想的性能。
2）决策树
用决策树来划分物体的类属，树中每一内部节点对应一个物体属性，而每一边对应于这些属性的可选值，树的叶节点则对应于物体的每个基本分类。
3）形式文法
在识别一个特定语言的学习中，通过对该语言的一系列表达式进行归纳，形成该语言的形式文法。
4）产生式规则
产生式规则表示为条件—动作对，已被极为广泛地使用。学习系统中的学习行为主要是：生成、泛化、特化（Specialization）或合成产生式规则。
5）形式逻辑表达式
形式逻辑表达式的基本成分是命题、谓词、变量、约束变量范围的语句，及嵌入的逻辑表达式。
6）图和网络
有的系统采用图匹配和图转换方案来有效地比较和索引知识。
7）框架和模式（schema）
每个框架包含一组槽，用于描述事物（概念和个体）的各个方面。
8）计算机程序和其它的过程编码
获取这种形式的知识，目的在于取得一种能实现特定过程的能力，而不是为了推断该过程的内部结构。
9）神经网络
这主要用在联接学习中。学习所获取的知识，最后归纳为一个神经网络。
10）多种表示形式的组合
有时一个学习系统中获取的知识需要综合应用上述几种知识表示形式。
根据表示的精细程度，可将知识表示形式分为两大类：泛化程度高的粗粒度符号表示、??泛化程度低的精粒度亚符号(sub-symbolic)表示。像决策树、形式文法、产生式规则、形式逻辑表达式、框架和模式等属于符号表示类；而代数表达式参数、图和网络、神经网络等则属亚符号表示类。
按应用领域分类
最主要的应用领域有：专家系统、认知模拟、规划和问题求解、数据挖掘、网络信息服务、图象识别、故障诊断、自然语言理解、机器人和博弈等领域。
从机器学习的执行部分所反映的任务类型上看，大部分的应用研究领域基本上集中于以下两个范畴：分类和问题求解。
（1）分类任务要求系统依据已知的分类知识对输入的未知模式（该模式的描述）作分析，以确定输入模式的类属。相应的学习目标就是学习用于分类的准则（如分类规则）。
（2）问题求解任务要求对于给定的目标状态,??寻找一个将当前状态转换为目标状态的动作序列；机器学习在这一领域的研究工作大部分集中于通过学习来获取能提高问题求解效率的知识（如搜索控制知识，启发式知识等）。
综合考虑各种学习方法出现的历史渊源、知识表示、推理策略、结果评估的相似性、研究人员交流的相对集中性以及应用领域等诸因素。将机器学习方法
 
区分为以下六类：
1）经验性归纳学习 (empirical inductive learning)
经验性归纳学习采用一些数据密集的经验方法（如版本空间法、ID3法，定律发现方法）对例子进行归纳学习。其例子和学习结果一般都采用属性、谓词、关系等符号表示。它相当于基于学习策略分类中的归纳学习，但扣除联接学习、遗传算法、加强学习的部分。
2）分析学习（analytic learning）
分析学习方法是从一个或少数几个实例出发，运用领域知识进行分析。其主要特征为：
·推理策略主要是演绎，而非归纳；
·使用过去的问题求解经验（实例）指导新的问题求解，或产生能更有效地运用领域知识的搜索控制规则。
分析学习的目标是改善系统的性能，而不是新的概念描述。分析学习包括应用解释学习、演绎学习、多级结构组块以及宏操作学习等技术。
3）类比学习
它相当于基于学习策略分类中的类比学习。在这一类型的学习中比较引人注目的研究是通过与过去经历的具体事例作类比来学习，称为基于范例的学习(case_based learning)，或简称范例学习。
4）遗传算法（genetic algorithm）
遗传算法模拟生物繁殖的突变、交换和达尔文的自然选择（在每一生态环境中适者生存）。它把问题可能的解编码为一个向量，称为个体，向量的每一个元素称为基因，并利用目标函数（相应于自然选择标准）对群体（个体的集合）中的每一个个体进行评价，根据评价值（适应度）对个体进行选择、交换、变异等遗传操作，从而得到新的群体。遗传算法适用于非常复杂和困难的环境，比如，带有大量噪声和无关数据、事物不断更新、问题目标不能明显和精确地定义，以及通过很长的执行过程才能确定当前行为的价值等。同神经网络一样，遗传算法的研究已经发展为人工智能的一个独立分支，其代表人物为霍勒德（J.H.Holland）。
5）联接学习
典型的联接模型实现为人工神经网络，其由称为神经元的一些简单计算单元以及单元间的加权联接组成。
6）增强学习（reinforcement learning）
增强学习的特点是通过与环境的试探性（trial and error）交互来确定和优化动作的选择，以实现所谓的序列决策任务。在这种任务中，学习机制通过选择并执行动作，导致系统状态的变化，并有可能得到某种强化信号（立即回报），从而实现与环境的交互。强化信号就是对系统行为的一种标量化的奖惩。系统学习的目标是寻找一个合适的动作选择策略，即在任一给定的状态下选择哪种动作的方法，使产生的动作序列可获得某种最优的结果（如累计立即回报最大）。
在综合分类中,经验归纳学习、遗传算法、联接学习和增强学习均属于归纳学习，其中经验归纳学习采用符号表示方式，而遗传算法、联接学习和加强学习则采用亚符号表示方式；分析学习属于演绎学习。
实际上，类比策略可看成是归纳和演绎策略的综合。因而最基本的学习策略只有归纳和演绎。
从学习内容的角度看，采用归纳策略的学习由于是对输入进行归纳，所学习的知识显然超过原有系统知识库所能蕴涵的范围,所学结果改变了系统的知识演绎闭包, 因而这种类型的学习又可称为知识级学习;而采用演绎策略的学习尽管所学的知识能提高系统的效率，但仍能被原有系统的知识库所蕴涵,即所学的知识未能改变系统的演绎闭包,因而这种类型的学习又被称为符号级学习。
1）监督学习(supervised learning)
监督学习，即在机械学习过程中提供对错指示。一般是在数据组中包含最终结果（0，1）。通过算法让机器自我减少误差。这一类学习主要应用于分类和预测 (regression &amp; classify)。监督学习从给定的训练数据集中学习出一个函数，当新的数据到来时，可以根据这个函数预测结果。监督学习的训练集要求是包括输入和输出，也可以说是特征和目标。训练集中的目标是由人标注的。常见的监督学习算法包括回归分析和统计分类。
2）非监督学习(unsupervised learning)
非监督学习又称归纳性学习（clustering）利用K方式(Kmeans)，建立中心（centriole），通过循环和递减运算(iteration&amp;descent)来减小误差，达到分类的目的。
机器学习领域的研究工作主要围绕以下三个方面进行：
（1）面向任务的研究
研究和分析改进一组预定任务的执行性能的学习系统。
（2）认知模型
研究人类学习过程并进行计算机模拟。
（3）理论分析
从理论上探索各种可能的学习方法和独立于应用领域的算法
机器学习是继专家系统之后人工智能应用的又一重要研究领域，也是人工智能和神经计算的核心研究课题之一。现有的计算机系统和人工智能系统没有什么学习能力，至多也只有非常有限的学习能力，因而不能满足科技和生产提出的新要求。对机器学习的讨论和机器学习研究的进展，必将促使人工智能和整个科学技术的进一步发展 。
作者：
（美）Tom Mitchell
语种：
简体中文
ISBN：
7-111-10993-7
开本：
16开
定价：
35.00元
原书名：
Machine Learning
页数：
280
属性分类：
教材
出版日期：
2003-01-01
所属丛书：
计算机类丛书
译者：
曾华军 张银奎 等
试用专业：
计算机
图书分类：
计算机&gt;人工智能&gt;综合
包含CD：
否
原出版社：
无
出版社：
机械工业出版社
绝版：
否
本书展示了机器学习中核心的算法和理论，并阐明了算法的运行过程。本书综合了许多的研究成果，例如统计学、人工智能、哲学、信息论、生物学、认知科学、计算复杂性和控制论等，并以此来理解问题的背景、算法和其中的隐含假定。本书可作为计算机专业
本科生、研究生教材，也可作为相关领域研究人员、教师的参考书。
TOM M.Mitchell是卡内基梅隆大学的教授，讲授“机器(AAA)的主席：美国《Machine Learning》杂志、国际机器学习年度会议（ICML）的创始人：多种技术杂志的撰稿人，曾发表过许多文章，出版过多本专著，是机器学习领域的著名学者。
机器学习这门学科所关注的问题是：计算机程序如何随着经验积累自动提高性能。机器学习已经被成功地应用于很多领域，从检测信用卡交易欺诈的数据挖掘程序，到获取户阅读兴趣的信息过滤系统，再到能在高速公路上自动行驶的汽车。同时，这个学科的基理论和算法也有了重大进展。
这本教材的目标是展现机器学习中核心的算法和理论。机器学习从很多学科吸收了成果和概念，包括统计学、人工智能、哲学、信息论、生物学、认知科学、计算复杂性和控制等。笔者相信，研究机器学习的最佳途径是从这些学科的观点看待机器学习，并且以此来理解问题的背景、算法以及其中隐含的假定。这些在以往很难做到，因为在这一领域缺少包容广泛的原始资料，本书的主要目的就是提供这样的一份资料。
由于素材的多学科性，本书不要求读者具有相应的知识背景，而是在必要时介绍其他一些学科的基本概念，如统计学、人工智能、信息论等。介绍的重点是与机器学习关系最密切甲那些概念。本书可以作为计算机科学与工程、统计学和社会科学等专业的大学生或研究生的教材，也可作为软件研究人员或从业人员的参考资料。
指导本书写作的两条原则为：第一，它是在校大学生可以理解的；第二，它应该包含我希望我自己的博士生在开始他们的器学习研究前要掌握的内容。
指导本书写作的第三条原则是：它应该体现理论和实践间的均衡。机器学习理论致力于回答这样的问题“学习性能是怎样随着给定的训练样例的数量而变化的?”和“对于各种同类型的学习任务：哪个学习算法最适合?”利用来自统计学、计算复杂性和贝叶斯分析的理论成果，这本书讨论了这一类理论问题。同时本书也涵盖很多实践方面的内容：介绍了这一领域的主要算法，阐明了算法的运行过程。
其中一些算法的实现和数据可以在因特网上通过网址http：//www．cs．cmu．edu/-tom/mlbook．html得到，包括用于人脸识别的神经网络的源代码和数据、用于信贷分析的决策树学习的源代码和数据及分析文本文档的贝叶分类器的源代码和数据。我很感谢那些帮助我创建这些在线资源的同事，他们是：Jason Rennie、Paul Hsiung、Jeff Shufelt、Matt Glickman、Scott Davies、Joseph O’Sullivan、Ken Lang\Andrew McCallum和Thorsten Joachims。
第1章　引言
1．1　学习问题的标准描述
1．2　设计-个学习系统
1．2．1　选择训练经验
1．2．2　选择目标函数
1．2．3　选择目标函数的表示
1. 2．4　选择函数逼近算法
1．2．5　最终设计
1．3　机器学习的一些观点和问题
1．4　如何阅读本书
1．5　小结和补充读物
习题
第2章　概念学习和一般到特殊序
2．1　简介
2．2　概念学习任务
2．2．1　术语定义
2．2．2　归纳学习假设
2．3　作为搜索的概念学习
2．4　FIND-S：寻找极大特殊假设
2．5　变型空间和候选消除算法
2．5．1　表示
2．5．2　列表后消除算法
2．5．3　变型空间的更简洁表示
2．5．4　候选消除学习算法
2．5．5　算法的举例
2．6　关于变型空间和候选消除的说明
2．6．1　候选消除算法是否会收敛到正确的假设
2．6．2　下一步需要什么样的训练样例
2．6．3　怎样使用不完全学习概念
2．7　归纳偏置
2．7．1　-个有偏的假设空间
2．7．2　无偏的学习器
2．7．3　无偏学习的无用性
2．8　小始和补充读物
习题
第3章　决策树学习
3．1　简介
3．2　决策树表示法
3．3　决策树学习的适用问题
3．4　基本的决策树学习算法
3．4．1　哪个属性是最佳的分类属性
3．4．2　举例
3．5　决策树学习中的假设空间搜索
3．6　决策树学习的归纳偏置
3．6．1　限定偏置和优选偏置
3．6．2　为什么短的假设优先
3．7　决策树学习的常见问题
3．7．1　避免过度拟合数据
3. 7．2　合并连续值属性
3．7．3　属性选择的其他度量标准
3．7．4　处理缺少属性值的训练样例
3．7．5　处理不同代价的属性
3．8　小结和补充读物
习题
第4章　人工神经网络
4．1　简介
4．2　神经网络表示
4．3　适合神经网络学习的问题
4．4　感知器
4．4．1　感知器的表征能力
4. 4．2　感知器训练法则
4．4．3　梯度下降和delta法则
4．4．4　小结
4．5　多层网络和反向传播算法
4．5．1　可微阈值单元
4．5．2　反向传播算法
4．5．3　反向传播法则的推导
4．6　反向传播算法的说明
4．6．1　收敛性和局部极小值
4．6．2　前馈网络的表征能力
4．6．3　假设空间搜索和归纳偏置
4．6．4　隐藏层表示
4．6．5　泛化、过度拟合和停止判据
4．7　举例：人脸识别
4．7．1　任务
4．7．2　设计要素
4．7．3　学习到的隐藏层表示
4．8　人工神经网络的高级课题
4．8．1　其他可选的误差函数
4．8．2　其他可选的误差最小化过程
4．8．3　递归网络
4．8．4　动态修改网络结构
4．9　小结和补充读物
习题
第5章　评估假设
5．1　动机
5．2　估计假设精度
5．2．1　样本错误率和真实错误率
5．2．2　离散值假设的置信区间
5．3　采样理论基础
5．3．1　错误率估计和二项比例估计
5．3．2　二项分布
5．3．3　均值和方差
5．3．4　估计量、偏差和方差
5．3．5　置信区间
5．3．6　双侧和单侧边界
5．4　推导置信区间的一般方法
5．5　两个假设错误率间的差异
5．6　学习算法比较
5．6. 1　配对t测试
5．6．2　实际考虑
5．7　小结和补充读物
习题
第6章　贝叶斯学习
6．1　简介
6．2　贝叶斯法则
6．3　贝叶斯法则和概念学习
6．3．1　BRUTE-FORCE贝叶斯概念学习
6．3．2　MAP假设和一致学习器
6．4　极大似然和最小误差平方假设
6．5　用于预测概率的极大似然假设
6．6　最小描述长度准则
6．7　贝叶斯最优分类器
6．8　GIBBS算法
6．9　朴素贝叶斯分类器
6．10　举例：学习分类文本
6．11　贝叶斯信念网
6．11．1　条件独立性
6．11．2　表示
6．11．3　推理
6．11．4　学习贝叶斯信念网
6．11．5　贝叶斯网的梯度上升训练
6．11．6　学习贝叶斯网的结构
6．12　EM算法
6．12．1　估计k个高斯分布的均值
6．12．2　EM算法的一般表述
6．12．3　k均值算法的推导
6．13　小结和补充读物
习题
第7章　计算学习理论
7．1　简介
7．2　可能学习近似正确假设
7．2．1　问题框架
7．2．2　假设的错误率
7．2．3　PAC可学习性
7．3　有限假设空间的样本复杂度
7．3．1　不可知学习和不一致假设
7．3．2　布尔文字的合取是PAC可学习的
7．3．3　其他概念类别的PAC可学习性
7．4　无限假设空间的样本复杂度
7．4．1　打散一个实例集合
7．4．2　Vapnik-Chervonenkis维度
7．4．3　样本复杂度和VC维
7．4．4　神经网络的VC维
7．5　学习的出错界限模型
7．5．1　FIND-S算法的出错界限
7．5．2　HALVING算法的出错界限
7．5．3　最优出错界限
7．5．4　加权多数算法
7．6　小结和补充读物
习题
第8章　基于实例的学习
8．1　简介
8．2　k-近邻算法
8．2．1　距离加权最近邻算法
8．2．2　对k-近邻算法的说明
8．2．3　术语注解
8．3　局部加权回归
8．3．1　局部加权线性回归
8．3．2　局部加权回归的说明
8．4　径向基函数
8．5　基于案例的推理
8．6　对消极学习和积极学习的评论
8．7　小结和补充读物
习题
第9章　遗传算法
9．1　动机
9．2　遗传算法
9．2．1　表示假设
9．2．2　遗传算子
9．2．3　适应度函数和假设选择
9．3　举例
9．4　假设空间搜索
9．5　遗传编程
9．5．1　程序表示
9．5．2　举例
9．5．3　遗传编程说明
9．6　进化和学习模型
9．6．1　拉马克进化
9．6．2　鲍德温效应
9．7　并行遗传算法
9．8　小结和补充读物
习题
第10章　学习规则集合
10．1　简介
10．2　序列覆盖算法
10．2．1　一般到特殊的柱状搜索
10．2．2　几种变型
10．3　学习规则集：小结
10．4　学习一阶规则
10．4．1　一阶Horn子句
10．4．2　术语
10．5　学习一阶规则集：FOIL
10．5．1　FOIL中的候选特化式的生成
10．5．2　引导FOIL的搜索
10．5．3　学习递归规则集
10．5．4　FOIL小结
10．6　作为逆演绎的归纳
10．7　逆归纳
10．7．1　一阶归纳
10．7．2　逆归纳：一阶情况
10．7．3　逆归纳小结
10．7．4　泛化、-包容和涵蕴
10．7．5　PROGOL
10．8　小结和补充读物
习题
第11章　分析学习
11．1　简介
11．2　用完美的领域理论学习：PROLOG-EBG
11．3　对基于解释的学习的说明
11．3．1　发现新特征
11．3．2　演绎学习
11．3．3　基于解释的学习的归纳偏置
11．3．4　知识级的学习
11．4　搜索控制知识的基于解释的学习
11．5　小结和补充读物
习题
第12章　归纳和分析学习的结合
12．1　动机
12．2　学习的归纳-分析途径
12．2．1　学习问题
12．2．2　假设空间搜索
12．3　使用先验知识得到初始假设
12．3．1　KBANN算法
12．3．2　举例
12．3．3　说明
12．4　使用先验知识改变搜索目标
12．4．1　TANGENTPROP算法
12．4．2　举例
12．4．3　说明
12．4．4　EBNN算法
12．4．5　说明
12．5　使用先验知识来扩展搜索算子
12．5．1　FOCL算法
12．5．2　说明
12．6　研究现状
12．7　小结和补充读物
习题
第13章　增强学习
13．1　简介
13．2　学习任务
13．3　Q学习
13．3．1　Q函数
13．3．2　一个学习Q的算法
13．3．3　举例
13．3．4　收敛性
13．3．5　实验策略
13．3．6　更新序列
13．4　非确定性回报和动作
13．5　时间差分学习
13．6　从样例中泛化
13．7　与动态规划的联乐
13．8　小结和补充读物
习题
附录　符号约定
原作名:Machine Learning for Hackers
作者:（美）Drew Conway/John Myles White　　译者:陈开江/刘逸哲/孟晓楠/罗森林 审校　　出版社:机械工业出版社　　页数:320　　定价:69.00　　ISBN:9787111417316
这本书为机器学习技术提供了一些非常棒的案例研究。它并不想成为一本关于机器学习的工具书或者理论书籍，它注重的是一个学习的过程，因而对于任何有一些编程背景和定量思维的人来说，它都是不错的选择。
——Max Shron OkCupid
机器学习是计算机科学和人工智能中非常重要的一个研究领域，机器学习不但在计算机科学的众多领域中大显身手，而且成为一些交叉学科的重要支撑技术。本书比较全面系统地介绍了机器学习的方法和技术，不仅详细阐述了许多经典的学习方法，还讨论了一些有生命力的新理论、新方法。



全书案例既有分类问题，也有回归问题；既包含监督学习，也涵盖无监督学习。本书讨论的案例从分类讲到回归，然后讨论了聚类、降维、最优化问题等。这些案例包括分类：垃圾邮件识别，排序：智能收件箱，回归模型：预测网页访问量，正则化：文本回归，最优化：密码破解，无监督学习：构建股票市场指数，空间相似度：用投票记录对美国参议员聚类，推荐系统：给用户推荐R语言包，社交网络分析：在Twitter上感兴趣的人，模型比较：给你的问题找到最佳算法。各章对原理的叙述力求概念清晰、表达准确，突出理论联系实际，富有启发性，易于理解。在探索这些案例的过程中用到的基本工具就是R统计编程语言。R语言非常适合用于机器学习的案例研究，因为它是一种用于数据分析的高水平、功能性脚本语言。
本书主要内容：
开发一个朴素贝叶斯分类器，仅仅根据邮件的文本信息来判断这封邮件是否是垃圾邮件；
使用线性回归来预测互联网排名前1000网站的PV；
利用文本回归理解图书中词与词之间的关系；
通过尝试破译一个简单的密码来学习优化技术；
利用无监督学习构建股票市场指数，用于衡量整体市场行情的好坏；
根据美国参议院的投票情况，从统计学的角度对美国参议员聚类；
通过K近邻算法构建向用户推荐R语言包；
利用Twitter数据来构建一个“你可能感兴趣的人”的推荐系统；
模型比较：给你的问题找到最佳算法。
Drew Conway 机器学习专家，拥有丰富的数据分析与处理工作经验。主要利用数学、统计学和计算机技术研究国际关系、冲突和恐怖主义等。他曾作为研究员在美国情报和国防部门供职数年。他拥有纽约大学政治系博士学位，曾为多种杂志撰写文章，是机器学习领域的著名学者。
John Myles White 机器学习专家，拥有丰富的数据分析与处理工作经验。主要从理论和实验的角度来研究人类如何做出决定，同时还是几个流行的R语言程序包的主要维护者，包括ProjectTemplate和log4r。他拥有普林斯顿大学哲学系博士学位，曾为多家技术杂志撰稿，发表过许多关于机器学习的论文，并在众多国际会议上发表演讲。
罗森林
博士，教授，博导。现任北京理工大学信息系统及安全对抗实验中心主任、专业责任教授。国防科技工业局科学技术委员会成员；《中国医学影像技术杂志》、《中国介入影像与治疗学》编委会委员；全国大学生信息安全技术专题邀请赛专家组副组长；中国人工智能学会智能信息安全专业委员会委员等。主要研究方向为信息安全、数据挖掘、媒体计算、中文信息处理等。负责或参加完成国家自然科学基金、国家科技支撑计划、863计划、国家242计划等省部级以上项目40余项。已发表学术论文90余篇，出版著作8部，出版译著1部，获授权专利3项。
陈开江
新浪微博搜索部研发工程师，曾独立负责微博内容反垃圾系统、微博精选内容挖掘算法、自助客服系统（包括自动回复、主动挖掘、舆情监测）等项目，主要从事社交挖掘、推荐算法研究、机器学习、自然语言处理相关工作，研究兴趣是社交网络的个性化推荐。
刘逸哲
阿里巴巴，CBU基础平台部搜索与推荐团队核心技术与query分析方向负责人，机器学习技术领域及圈子负责人。曾任中国雅虎相关性团队、自然语言处理团队算法工程师；AvePoint.inc开发工程师，从事企业级搜索引擎开发。研究兴趣是机器学习、自然语言处理及个性化推荐等算法在大规模数据上的应用。
孟晓楠
一淘广告技术，阿里非搜索广告算法负责人，负责用户行为分析、建模与细分，RTB竞价算法，展示广告CTR预估与SEM优化。曾工作于网易杭州研究院，参与过分布式全文检索系统和网易博客产品的数据挖掘算法开发。研究兴趣是计算广告技术、机器学习、大数据技术、信息检索等。
