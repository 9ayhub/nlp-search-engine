语音识别是一门交叉学科。近二十年来，语音识别技术取得显著进步，开始从实验室走向市场。人们预计，未来10年内，语音识别技术将进入工业、家电、通信、汽车电子、医疗、家庭服务、消费电子产品等各个领域。 语音识别听写机在一些领域的应用被美国新闻界评为1997年计算机发展十件大事之一。很多专家都认为语音识别技术是2000年至2010年间信息技术领域十大重要的科技发展技术之一。 语音识别技术所涉及的领域包括：信号处理、模式识别、概率论和信息论、发声机理和听觉机理、人工智能等等。
与机器进行语音交流，让机器明白你说什么，这是人们长期以来梦寐以求的事情。中国物联网校企联盟形象得把语音识别
 
比做为“机器的听觉系统”。语音识别技术就是让机器通过识别和理解过程把语音信号转变为相应的文本或命令的高技术。　语音识别技术主要包括特征提取技术、模式匹配准则及模型训练技术三个方面。语音识别技术车联网也得到了充分的引用，例如在翼卡车联网中，只需按一键通客服人员口述即可设置目的地直接导航，安全、便捷。

1952年贝尔研究所Davis等人研究成功了世界上第一个能识别10个英文数字发音的实验系统。
1960年英国的Denes等人研究成功了第一个计算机语音识别系统。
大规模的语音识别
 
研究是在进入了70年代以后，在小词汇量、孤立词的识别方面取得了实质性的进展。
进入80年代以后，研究的重点逐渐转向大词汇量、非特定人连续语音识别。在研究思路上也发生了重大变化，即由传统的基于标准模板匹配的技术思路开始转向基于统计模型 (HMM）的技术思路。此外，再次提出了将神经网络技术引入语音识别问题的技术思路。
进入90年代以后，在语音识别的系统框架方面并没有什么重大突破。但是，在语音识别技术的应用及产品化方面出现了很大的进展。
DARPA(Defense Advanced Research Projects Agency）是在70年代由美国国防部远景研究计划局资助的一项10年计划，其旨在支持语言理解系统的研究开发工作。
到了80年代，美国国防部远景研究计划局又资助了一项为期10年的DARPA战略计划，其中包括噪声下的语音识别和会话（口语）识别系统，识别任务设定为“（1000单词）连续语音数据库管理”。
到了90年代，这一DARPA计划仍在持续进行中。其研究重点已转向识别装置中的自然语言处理部分，识别任务设定为“航空旅行信息检索”。
日本也在1981年的第五代计算机计划中提出了有关语音识别输入-输出自然语言的宏伟目标，虽然没能实现预期目标，但是有关语音识别技术的研究有了大幅度的加强和进展。
1987年起，日本又拟出新的国家项目---高级人机口语接口和自动电话翻译系统。
中国的语音识别研究起始于1958年，由中国科学院声学所利用电子管电路识别10个元音。直至1973年才由中国科学院声学所开始计算机语音识别。由于当时条件的限制，中国的语音识别研究工作一直处于缓慢发展的阶段。
进入80年代以后，随着计算机应用技术在中国逐渐普及和应用以及数字信号技术的进一步发展，国内许多单位具备了研究语音技术的基本条件。与此同时，国际上语音识别技术在经过了多年的沉寂之后重又成为研究的热点，发展迅速。就在这种形式下，国内许多单位纷纷投入到这项研究工作中去。
1986年3月中国高科技发展计划（863计划）启动，语音识别作为智能计算机系统研究的一个重要组成部分而被专门列为研究课题。在863计划的支持下，中国开始了有组织的语音识别技术的研究，并决定了每隔两年召开一次语音识别的专题会议。从此中国的语音识别技术进入了一个前所未有的发展阶段。
这一时期的语音识别方法基本上是采用传统的模式识别策略。其中以苏联的Velichko和Zagoruyko、日本的迫江和千叶，以及当时在美国的板仓等人的研究工作最具有代表性。
· 苏联的研究为模式识别应用于语音识别这一领域奠定了基础；
· 日本的研究则展示了如何利用动态规划技术在待识语音模式与标准语音模式之间进行非线性时间匹配的方法；
·板仓的研究提出了如何将线性预测分析技术（LPC）加以扩展，使之用于语音信号的特征抽取的方法。
在语音识别的研究发展过程中，相关研究人员根据不同语言的发音特点，设计和制作了以汉语（包括不同方言）、英语等各类语言的语音数据库，这些语音数据库可以为国内外有关的科研单位和大学进行汉语连续语音识别算法研究、系统设计、及产业化工作提供充分、科学的训练语音样本。例如：MIT Media lab Speech Dataset（麻省理工学院媒体实验室语音数据集）、Pitch and Voicing Estimates for Aurora 2(Aurora2语音库的基因周期和声调估计）、Congressional speech data（国会语音数据）、Mandarin Speech Frame Data（普通话语音帧数据）、用于测试盲源分离算法的语音数据等。
目前在大词汇语音识别方面处于领先地位的IBM语音研究小组，就是在70年代开始了它的大词汇语音识别研究工作的。AT&amp;T的贝尔研究所也开始了一系列有关非特定人语音识别的实验。这一研究历经10年，其成果是确立了如何制作用于非特定人语音识别的标准模板的方法。
这一时期所取得的重大进展有：
⑴隐马尔可夫模型（HMM）技术的成熟和不断完善成为语音识别的主流方法。
⑵以知识为基础的语音识别的研究日益受到重视。在进行连续语音识别的时候，除了识别声学信息外，更多地利用各种语言知识，诸如构词、句法、语义、对话背景方面等的知识来帮助进一步对语音作出识别和理解。同时在语音识别研究领域，还产生了基于统计概率的语言模型。
⑶人工神经网络在语音识别中的应用研究的兴起。在这些研究中，大部分采用基于反向传播算法（BP算法）的多层感知网络。人工神经网络具有区分复杂的分类边界的能力，显然它十分有助于模式划分。特别是在电话语音识别方面，由于其有着广泛的应用前景，成了当前语音识别应用的一个热点。
另外，面向个人用途的连续语音听写机技术也日趋完善。这方面，最具代表性的是IBM的ViaVoice和Dragon公司的Dragon Dictate系统。这些系统具有说话人自适应能力，新用户不需要对全部词汇进行训练，便可在使用中不断提高识别率。
中国的语音识别技术的发展 ：　⑴在北京有中科院声学所、自动化所、清华大学、北方交通大学等科研机构和高等院校。另外，还有哈尔滨工业大学、中国科技大学、四川大学等也纷纷行动起来。
⑵现在，国内有不少语音识别系统已研制成功。这些系统的性能各具特色。
· 在孤立字大词汇量语音识别方面，最具代表性的要数92年清华大学电子工程系与中国电子器件公司合作研制成功的THED-919特定人语音识别与理解实时系统。
· 在连续语音识别方面，91年12月四川大学计算机中心在微机上实现了一个主题受限的特定人连续英语——汉语语音翻译演示系统。
·在非特定人语音识别方面，有清华大学计算机科学与技术系在87年研制的声控电话查号系统并投入实际使用。
根据识别的对象不同，语音识别任务大体可分为3类，即孤立词识别（isolated word recognition），关键词识别（或称关键词检出，keyword spotting）和连续语音识别。其中，孤立词识别 的任务是识别事先已知的孤立的词，如“开机”、“关机”等；连续语音识别的任务则是识别任意的连续语音，如一个句子或一段话；连续语音流中的关键词检测针对的是连续语音，但它并不识别全部文字，而只是检测已知的若干关键词在何处出现，如在一段话中检测“计算机”、“世界”这两个词。
根据针对的发音人，可以把语音识别技术分为特定人语音识别和非特定人语音识别，前者只能识别一个或几个人的语音，而后者则可以被任何人使用。显然，非特定人语音识别系统更符合实际需要，但它要比针对特定人的识别困难得多。
另外，根据语音设备和通道，可以分为桌面（PC）语音识别、电话语音识别和嵌入式设备（手机、PDA等）语音识别。不同的采集通道会使人的发音的声学特性发生变形，因此需要构造各自的识别系统。
语音识别的应用领域非常广泛，常见的应用系统有：语音输入系统，相对于键盘输入方法，它更符合人的日常习惯，也更自然、更高效；语音控制系统，即用语音来控制设备的运行，相对于手动控制来说更加快捷、方便，可以用在诸如工业控制、语音拨号系统、智能家电、声控智能玩具等许多领域；智能对话查询系统，根据客户的语音进行操作，为用户提供自然、友好的数据库检索服务，例如家庭服务、宾馆服务、旅行社服务系统、订票系统、医疗服务、银行服务、股票查询服务等等。
语音识别方法主要是模式匹配法。
在训练阶段，用户将词汇表中的每一词依次说一遍，并且将其特征矢量作为模板存入模板库。
在识别阶段，将输入语音的特征矢量依次与模板库中的每个模板进行相似度比较，将相似度最高者作为识别结果输出。
语音识别主要有以下五个问题：
⒈对自然语言的识别和理解。首先必须将连续的讲话分解为词、音素等单位，其次要建立一个理解语义的规则。
⒉语音信息量大。语音模式不仅对不同的说话人不同，对同一说话人也是不同的，例如，一个说话人在随意说话和认真说话时的语音信息是不同的。一个人的说话方式随着时间变化。
⒊语音的模糊性。说话者在讲话时，不同的词可能听起来是相似的。这在英语和汉语中常见。
⒋单个字母或词、字的语音特性受上下文的影响，以致改变了重音、音调、音量和发音速度等。
⒌环境噪声和干扰对语音识别有严重影响，致使识别率低。
前端处理是指在特征提取之前，先对原始语音进行处理，部分消除噪声和不同说话人带来的影响，使处理后的信号更能反映语音的本质特征。最常用的前端处理有端点检测和语音增强。端点检测是指在语音信号中将语音和非语音信号时段区分开来，准确地确定出语音信号的起始点。经过端点检测后，后续处理就可以只对语音信号进行，这对提高模型的精确度和识别正确率有重要作用。语音增强的主要任务就是消除环境噪声对语音的影响。目前通用的方法是采用维纳滤波，该方法在噪声较大的情况下效果好于其它滤波器。
声学特征的提取与选择是语音识别的一个重要环节。声学特征的提取既是一个信息大幅度压缩的过程，也是一个信号解卷过程，目的是使模式划分器能更好地划分。由于语音信号的时变特性，特征提取必须在一小段语音信号上进行，也即进行短时分析。这一段被认为是平稳的分析区间称之为帧，帧与帧之间的偏移通常取帧长的1/2或1/3。通常要对信号进行预加重以提升高频，对信号加窗以避免短时语音段边缘的影响。
线性预测分析从人的发声机理入手，通过对声道的短管级联模型的研究，认为系统的传递函数符合全极点数字滤波器的形式，从而n 时刻的信号可以用前若干时刻的信号的线性组合来估计。通过使实际语音的采样值和线性预测采样值之间达到均方差最小LMS，即可得到线性预测系数LPC。对 LPC的计算方法有自相关法（德宾Durbin法）、协方差法、格型法等等。计算上的快速有效保证了这一声学特征的广泛使用。与LPC这种预测参数模型类似的声学特征还有线谱对LSP、反射系数等等。
利用同态处理方法，对语音信号求离散傅立叶变换DFT后取对数，再求反变换iDFT就可得到倒谱系数。对LPC倒谱（LPCCEP），在获得滤波器的线性预测系数后，可以用一个递推公式计算得出。实验表明，使用倒谱可以提高特征参数的稳定性。
不同于LPC等通过对人的发声机理的研究而得到的声学特征，Mel倒谱系数MFCC和感知线性预测 PLP是受人的听觉系统研究成果推动而导出的声学特征。对人的听觉机理的研究发现，当两个频率相近的音调同时发出时，人只能听到一个音调。临界带宽指的就是这样一种令人的主观感觉发生突变的带宽边界，当两个音调的频率差小于临界带宽时，人就会把两个音调听成一个，这称之为屏蔽效应。Mel刻度是对这一临界带宽的度量方法之一。
首先用FFT将时域信号转化成频域，之后对其对数能量谱用依照Mel刻度分布的三角滤波器组进行卷积，最后对各个滤波器的输出构成的向量进行离散余弦变换DCT，取前N个系数。PLP仍用德宾法去计算LPC参数，但在计算自相关参数时用的也是对听觉激励的对数能量谱进行DCT的方法。
语音识别系统的模型通常由声学模型和语言模型两部分组成，分别对应于语音到音节概率的计算和音节到字概率的计算。本节和下一节分别介绍声学模型和语言模型方面的技术。
HMM声学建模：马尔可夫模型的概念是一个离散时域有限状态自动机，隐马尔可夫模型HMM是指这一马尔可夫模型的内部状态外界不可见，外界只能看到各个时刻的输出值。对语音识别系统，输出值通常就是从各个帧计算而得的声学特征。用HMM刻画语音信号需作出两个假设，一是内部状态的转移只与上一状态有关，另一是输出值只与当前状态（或当前的状态转移）有关，这两个假设大大降低了模型的复杂度。HMM的打分、解码和训练相应的算法是前向算法、Viterbi算法和前向后向算法。
语音识别中使用HMM通常是用从左向右单向、带自环、带跨越的拓扑结构来对识别基元建模，一个音素就是一个三至五状态的HMM，一个词就是构成词的多个音素的HMM串行起来构成的HMM，而连续语音识别的整个模型就是词和静音组合起来的HMM。
上下文相关建模：协同发音，指的是一个音受前后相邻音的影响而发生变化，从发声机理上看就是人的发声器官在一个音转向另一个音时其特性只能渐变，从而使得后一个音的频谱与其他条件下的频谱产生差异。上下文相关建模方法在建模时考虑了这一影响，从而使模型能更准确地描述语音，只考虑前一音的影响的称为Bi- Phone，考虑前一音和后一音的影响的称为Tri-Phone。
英语的上下文相关建模通常以音素为基元，由于有些音素对其后音素的影响是相似的，因而可以通过音素解码状态的聚类进行模型参数的共享。聚类的结果称为senone。决策树用来实现高效的triphone对senone的对应，通过回答一系列前后音所属类别（元/辅音、清/浊音等等）的问题，最终确定其HMM状态应使用哪个senone。分类回归树CART模型用以进行词到音素的发音标注。
语言模型主要分为规则模型和统计模型两种。统计语言模型是用概率统计的方法来揭示语言单位内在的统计规律，其中N-Gram简单有效，被广泛使用。
N-Gram：该模型基于这样一种假设，第n个词的出现只与前面N-1个词相关，而与其它任何词都不相关，整句的概率就是各个词出现概率的乘积。这些概率可以通过直接从语料中统计N个词同时出现的次数得到。常用的是二元的Bi-Gram和三元的Tri-Gram。
语言模型的性能通常用交叉熵和复杂度（Perplexity）来衡量。交叉熵的意义是用该模型对文本识别的难度，或者从压缩的角度来看，每个词平均要用几个位来编码。复杂度的意义是用该模型表示这一文本平均的分支数，其倒数可视为每个词的平均概率。平滑是指对没观察到的N元组合赋予一个概率值，以保证词序列总能通过语言模型得到一个概率值。通常使用的平滑技术有图灵估计、删除插值平滑、Katz平滑和Kneser-Ney平滑。
连续语音识别中的搜索，就是寻找一个词模型序列以描述输入语音信号，从而得到词解码序列。搜索所依据的是对公式中的声学模型打分和语言模型打分。在实际使用中，往往要依据经验给语言模型加上一个高权重，并设置一个长词惩罚分数。
Viterbi：基于动态规划的Viterbi算法在每个时间点上的各个状态，计算解码状态序列对观察序列的后验概率，保留概率最大的路径，并在每个节点记录下相应的状态信息以便最后反向获取词解码序列。Viterbi算法在不丧失最优解的条件下，同时解决了连续语音识别中HMM模型状态序列与声学观察序列的非线性时间对准、词边界检测和词的识别，从而使这一算法成为语音识别搜索的基本策略。
由于语音识别对当前时间点之后的情况无法预测，基于目标函数的启发式剪枝难以应用。由于Viterbi算法的时齐特性，同一时刻的各条路径对应于同样的观察序列，因而具有可比性，束Beam搜索在每一时刻只保留概率最大的前若干条路径，大幅度的剪枝提高了搜索的效率。这一时齐Viterbi- Beam算法是当前语音识别搜索中最有效的算法。N-best搜索和多遍搜索：为在搜索中利用各种知识源，通常要进行多遍搜索，第一遍使用代价低的知识源，产生一个候选列表或词候选网格，在此基础上进行使用代价高的知识源的第二遍搜索得到最佳路径。此前介绍的知识源有声学模型、语言模型和音标词典，这些可以用于第一遍搜索。为实现更高级的语音识别或口语理解，往往要利用一些代价更高的知识源，如4阶或5阶的N-Gram、4阶或更高的上下文相关模型、词间相关模型、分段模型或语法分析，进行重新打分。最新的实时大词表连续语音识别系统许多都使用这种多遍搜索策略。
N-best搜索产生一个候选列表，在每个节点要保留N条最好的路径，会使计算复杂度增加到N倍。简化的做法是只保留每个节点的若干词候选，但可能丢失次优候选。一个折衷办法是只考虑两个词长的路径，保留k条。词候选网格以一种更紧凑的方式给出多候选，对N-best搜索算法作相应改动后可以得到生成候选网格的算法。
前向后向搜索算法是一个应用多遍搜索的例子。当应用简单知识源进行了前向的Viterbi搜索后，搜索过程中得到的前向概率恰恰可以用在后向搜索的目标函数的计算中，因而可以使用启发式的A算法进行后向搜索，经济地搜索出N条候选。
语音识别系统选择识别基元的要求是，有准确的定义，能得到足够数据进行训练，具有一般性。英语通常采用上下文相关的音素建模，汉语的协同发音不如英语严重，可以采用音节建模。系统所需的训练数据大小与模型复杂度有关。模型设计得过于复杂以至于超出了所提供的训练数据的能力，会使得性能急剧下降。
听写机：大词汇量、非特定人、连续语音识别系统通常称为听写机。其架构就是建立在前述声学模型和语言模型基础上的HMM拓扑结构。训练时对每个基元用前向后向算法获得模型参数，识别时，将基元串接成词，词间加上静音模型并引入语言模型作为词间转移概率，形成循环结构，用Viterbi算法进行解码。针对汉语易于分割的特点，先进行分割再对每一段进行解码，是用以提高效率的一个简化方法。
对话系统：用于实现人机口语对话的系统称为对话系统。受目前技术所限，对话系统往往是面向一个狭窄领域、词汇量有限的系统，其题材有旅游查询、订票、数据库检索等等。其前端是一个语音识别器，识别产生的N-best候选或词候选网格，由语法分析器进行分析获取语义信息，再由对话管理器确定应答信息，由语音合成器输出。由于目前的系统往往词汇量有限，也可以用提取关键词的方法来获取语义信息。
语音识别系统的性能受许多因素的影响，包括不同的说话人、说话方式、环境噪音、传输信道等等。提高系统鲁棒性，是要提高系统克服这些因素影响的能力，使系统在不同的应用环境、条件下性能稳定；自适应的目的，是根据不同的影响来源，自动地、有针对性地对系统进行调整，在使用中逐步提高性能。以下对影响系统性能的不同因素分别介绍解决办法。
解决办法按针对语音特征的方法（以下称特征方法）和模型调整的方法（以下称模型方法）分为两类。前者需要寻找更好的、高鲁棒性的特征参数，或是在现有的特征参数基础上，加入一些特定的处理方法。后者是利用少量的自适应语料来修正或变换原有的说话人无关（SI）模型，从而使其成为说话人自适应（SA）模型。
说话人自适应的特征方法有说话人规一化和说话人子空间法，模型方法有贝叶斯方法、变换法和模型合并法。
语音系统中的噪声，包括环境噪声和录音过程加入的电子噪声。提高系统鲁棒性的特征方法包括语音增强和寻找对噪声干扰不敏感的特征，模型方法有并行模型组合PMC方法和在训练中人为加入噪声。信道畸变包括录音时话筒的距离、使用不同灵敏度的话筒、不同增益的前置放大和不同的滤波器设计等等。特征方法有从倒谱矢量中减去其长时平均值和RASTA滤波，模型方法有倒谱平移。
微软在office和vista中都应用了自己开发的语音识别引擎，微软语音识别引擎的使用是完全免费的，所以产生了许多基于微软语音识别引擎开发的语音识别应用软件，例如《语音游戏大师》《语音控制专家》《芝麻开门》《警卫语音识别系统》等等软件。其中《警卫语音识别系统》是唯一可以控制单片机类的硬件设施！！
2009年微软发布windows 7操作系统，语音识别软件得到了更好的推广！
语音识别系统的性能指标主要有四项。①词汇表范围：这是指机器能识别的单词或词组的范围，如不作任何限制，则可认为词汇表范围是无限的。②说话人限制：是仅能识别指定发话者的语音，还是对任何发话人的语音都能识别。③训练要求：使用前要不要训练，即是否让机器先“听”一下给定的语音，以及训练次数的多少。④正确识别率：平均正确识别的百分数，它与前面三个指标有关。
以上介绍了实现语音识别系统的各个方面的技术。这些技术在实际使用中达到了较好的效果，但如何克服影响语音的各种因素还需要更深入地分析。目前听写机系统还不能完全实用化以取代键盘的输入，但识别技术的成熟同时推动了更高层次的语音理解技术的研究。由于英语与汉语有着不同的特点，针对英语提出的技术在汉语中如何使用也是一个重要的研究课题，而四声等汉语本身特有的问题也有待解决。
近几年来，特别是2009年以来，借助机器学习领域深度学习研究的发展，以及大数据语料的积累，语音识别技术得到突飞猛进的发展。
1、技术新发展
1）将机器学习领域深度学习研究引入到语音识别声学模型训练，使用带RBM预训练的多层神经网络，极大提高了声学模型的准确率。在此方面，微软公司的研究人员率先取得了突破性进展，他们使用深层神经网络模型（DNN）后，语音识别错误率降低了30%，是近20年来语音识别技术方面最快的进步。
2）目前大多主流的语音识别解码器已经采用基于有限状态机（WFST）的解码网络，该解码网络可以把语言模型、词典和声学共享音字集统一集成为一个大的解码网络，大大提高了解码的速度，为语音识别的实时应用提供了基础。
3）随着互联网的快速发展，以及手机等移动终端的普及应用，目前可以从多个渠道获取大量文本或语音方面的语料，这为语音识别中的语言模型和声学模型的训练提供了丰富的资源，使得构建通用大规模语言模型和声学模型成为可能。在语音识别中，训练数据的匹配和丰富性是推动系统性能提升的最重要因素之一，但是语料的标注和分析需要长期的积累和沉淀，随着大数据时代的来临，大规模语料资源的积累将提到战略高度。
2、技术新应用
近期，语音识别在移动终端上的应用最为火热，语音对话机器人、语音助手、互动工具等层出不穷，许多互联网公司纷纷投入人力、物力和财力展开此方面的研究和应用，目的是通过语音交互的新颖和便利模式迅速占领客户群。
目前，国外的应用一直以苹果的siri为龙头。
而国内方面，科大讯飞、云知声、盛大、捷通华声、搜狗语音助手、紫冬口译、百度语音等系统都采用了最新的语音识别技术，市面上其他相关的产品也直接或间接嵌入了类似的技术。
